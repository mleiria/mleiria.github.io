<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning-Blog</title>
    <description>A Deep Learning Blog</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    <author>
      <name>MLeiria</name>
      <email>manuel.leiria@gmail.com</email>
      <uri>https://ashishchaudhary.in/hacker-blog</uri>
    </author>
    
      <item>
        <title>Rede Neuronal - Afinar os Hyperparâmetros</title>
        <description>&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script id=&quot;MathJax-script&quot; async
          src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&quot;&gt;
&lt;/script&gt;


&lt;h2&gt;Introdução&lt;/h2&gt;
A flexibilidade de uma rede neuronal, proporcionada pelos diversos hyperparâmetros e das combinações entre eles que 
podemos fazer, traz-nos um drama: como seleccionar a melhor combinação entre eles. O problema é mesmo este,
são muitos hyperparâmetroe que podemos combinar. Até um caso simples de uma MLP (Multi Layer Perecepton), em termos de
hyperparâmetros, podemos seleccionar o nº de camadas (&lt;i&gt;layers&lt;/i&gt;), o número de unidades (&lt;i&gt;neurons&lt;/i&gt;) por
camada, a função de activação para cada camada, inicialização dos pesos (&lt;i&gt;weights&lt;/i&gt;), a taxa de 
aprendizagem (&lt;i&gt;learning rate&lt;/i&gt;), entre outros.
&lt;br&gt;
A opção mais simples é tentar várias combinações e ver qual destas traz melhores resultados no conjunto de dados
de validação.
&lt;br&gt;
Por exemplo, podemos usar o &lt;b&gt;&lt;i&gt;sklearn.model_selection.RandomizedSearchCV&lt;/i&gt;&lt;/b&gt; para explorar o espaço dos hyperparâmetros.
&lt;p&gt;
Nota: link para o jupyter notebook com o código completo: &lt;br&gt;
&lt;a href=&quot;https://github.com/mleiria/mleiria.github.io/blob/master/jupyter-notebook/FineTunning_NN-Hyperparams.ipynb&quot; target=&quot;_blank&quot;&gt;MLP_Regression_Synthetic_Data.ipynb&lt;/a&gt;
&lt;br&gt;ou Colab:&lt;br&gt;
&lt;a href=&quot;https://colab.research.google.com/drive/1ETQe_CNwZGQY-m9NkPhhc8hPlQOdan11?usp=sharing&quot; target=&quot;_blank&quot;&gt;MLP_Regression_Synthetic_Data.ipynb&lt;/a&gt;
&lt;/p&gt;

&lt;h2&gt;Modelo Keras&lt;/h2&gt;
Comecemos por importar as classes necessárias.
&lt;pre&gt;
import sklearn
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import reciprocal
from tensorflow import keras
from sklearn.model_selection import train_test_split
import numpy as np

print('The scikit-learn version is {}.'.format(sklearn.__version__))
&lt;/pre&gt;
&lt;b&gt;out:&lt;/b&gt;
&lt;pre&gt;
The scikit-learn version is 0.21.2.
&lt;/pre&gt;
Criar uma função que constrói e compila um modelo Keras, dados um conjunto de hyperparâmetros:
&lt;pre&gt;
def build_model(n_hidden=3, n_neurons=30, lr=1e-3, input_shape=[3]):
    &quot;&quot;&quot;
    Constrói um modelo Keras com base nos parâmetros de entrada.
    
    :param n_hidden: Número de camadas escondidas (hidden layers)
    :param n_neurons: Número de unidades por camada
    :param lr: Taxa de aprendizagem (learning rate)
    :param input_shape: Formato dos dados de entrada
    :return: Um modelo Keras do tipo Sequencial
    &quot;&quot;&quot;
    model = keras.models.Sequential()
    model.add(keras.layers.InputLayer(input_shape=input_shape))
    # com n_hidden camadas densas escondidas
    # Função de activação relu
    for i in range(n_hidden):
        model.add(keras.layers.Dense(n_neurons, activation='relu'))
    # Camada de saída
    # Perda medida pelo mse (mean squared error)
    # Optimizador SGD (Stochastic Gradiente Descent)
    model.add(keras.layers.Dense(1))
    model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=lr))
    return model
&lt;/pre&gt;
A função supra cria um modelo Sequencial simples para uma regressão univariada (só um neurónio de saída),
com um dado formato (ou dimensão) de dados de entrada (no exemplo, 3 &lt;i&gt;features&lt;/i&gt;) e dados o número de
camadas e neurónios por camada. De seguida o modelo é compilado e usa o optimizador SGD com a taxa de aprendizagem
também ela especificada como parâmetro de entrada. É boa prática fornecer sempre valores, razoáveis, por defeito 
ao maior número possível de hyperparâmetros.
&lt;br&gt;
&lt;h2&gt;Criar um regressor &lt;b&gt;&lt;i&gt;KerasRegressor&lt;/i&gt;&lt;/b&gt; com base na função &lt;b&gt;&lt;i&gt;build_model()&lt;/i&gt;&lt;/b&gt;&lt;/h2&gt;
&lt;pre&gt;keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)&lt;/pre&gt;
O objecto &lt;b&gt;&lt;i&gt;KerasRegressor&lt;/i&gt;&lt;/b&gt;é um &lt;i&gt;wrapper&lt;/i&gt; sobre o modelo Keras construído. Como não 
especificámos nenhum hyperparâmetro na sua criação, ele vai usar os valores por defeito que foram definidos
no &lt;b&gt;&lt;i&gt;build_model()&lt;/i&gt;&lt;/b&gt;. Agora podemos usar este objecto como um regressor Scikit-Learn, i.e., podemos
treiná-lo usando o método &lt;b&gt;&lt;i&gt;fit()&lt;/i&gt;&lt;/b&gt; e posteriormente avaliá-lo com o método &lt;b&gt;&lt;i&gt;score()&lt;/i&gt;&lt;/b&gt;. 
Finalmente, para as previsões usamos o método &lt;b&gt;&lt;i&gt;predict()&lt;/i&gt;&lt;/b&gt;. O código seguinte exemplifica:

&lt;pre&gt;
keras_reg.fit(x_train, y_train, epochs=100,
                  validation_data=(x_valid, y_valid),
                  callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])

mse_test = keras_reg.score(x_test, y_test)
y_pred = keras_reg.predict(x_new
&lt;/pre&gt;
 Qualquer parâmetro extra que passe para o método &lt;b&gt;&lt;i&gt;fit()&lt;/i&gt;&lt;/b&gt;, será passado para o modelo
 Keras subjacente. Atenção que o &lt;i&gt;score&lt;/i&gt; é o oposto do &lt;i&gt;MSE&lt;/i&gt; porque o Scikit-Learn recebe
 &lt;i&gt;scores&lt;/i&gt; e não perdas (i.e., quanto maior, melhor).
 &lt;p&gt;
 Agora o que queremos é testar várias combinações de hyperparâmetros e ver qual delas é a melhor. Como
 temos muitos hyperparâmetros, a pesquisa aleatória (&lt;i&gt;randomized search&lt;/i&gt;) faz mais sentido do que a pesquisa
 em rede (&lt;i&gt;grid search&lt;/i&gt;). Exploremos o número de camadas escondidas, neurónios e taxa de aprendizagem:
 &lt;/p&gt;
&lt;pre&gt;
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import reciprocal

search_params = {
    'n_hidden': [1, 3, 5, 7],
    'n_neurons': np.arange(1, 100),
    'lr': reciprocal(3e-4, 3e-2)
}

rnd_search = RandomizedSearchCV(keras_reg, search_params, cv=3, n_iter=10)
rnd_search.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid),
               callbacks=[keras.callbacks.EarlyStopping(patience=10)])	
&lt;/pre&gt;

Estes parâmetros extra que passamos para o método &lt;b&gt;&lt;i&gt;fit()&lt;/i&gt;&lt;/b&gt; serão passados para o modelo Keras.
Note-se que o &lt;b&gt;&lt;i&gt;RandomizedSearchCV&lt;/i&gt;&lt;/b&gt; usa a validação &lt;i&gt;K-fold cross validation&lt;/i&gt; de forma que 
não usa &lt;b&gt;&lt;i&gt;x_valid&lt;/i&gt;&lt;/b&gt; e &lt;b&gt;&lt;i&gt;y_valid&lt;/i&gt;&lt;/b&gt;. Estes só servem para o &lt;b&gt;&lt;i&gt;EarlyStopping&lt;/i&gt;&lt;/b&gt;.
Quando este procedimento acabar, podemos aceder aos melhores parâmetros e ao melhor score:

&lt;pre&gt;
print(rnd_search.best_params_)
print(rnd_search.best_score_)
&lt;/pre&gt;
&lt;h2&gt;Algumas considerações finais&lt;/h2&gt;
&lt;h3&gt;Número de camadas escondidas&lt;/h3&gt;
Para muitos problemas podemos começar com uma única camada escondida e quase de certeza que obtemos bons resultados.
Em princípio, uma MLP com uma só camada escondida consegue modelar qualquer função desde que tenha neurónios suficientes,
o que não quer dizer que seja a solução óptima. Para problemas complexos temos de encontrar o balanço entre o número de 
camadas escondidas e o número de neurónios por camada.
&lt;h3&gt;Número de neurónios por camada escondida&lt;/h3&gt;
O número de neurónios nas camadas de entrada e saída são dependentes do tipo de dados de entrada e pelo tipo de 
tarefa que temos em mãos. No exemplo supra, temos três neurónios de entrada (porque temos três features. No exemplo são 
dados sintéticos mas poderiam ser, por exemplo, o número de divisões de um apartamento, o total em metros quadrados do 
apartamento e a zona e o output seria o preço do apartamento) e um neurónio de saída.&lt;br&gt;
Para as camadas escondidas, era comum  escolher o número de neurónios de forma a fazer uma pirâmide com cada vez menos
neuŕonios em cada camada. Por exemplo, uma tipica rede neuronal para o conjunto de dados &lt;a href=&quot;https://en.wikipedia.org/wiki/MNIST_database&quot;&gt;MNIST&lt;/a&gt;
teria a seguinte arquitectura: 3 camadas escondidas, onde a primeira camada tem 300 neurónios, a segunda 200 e a terceira 100.
Esta prática tem sido abandonada porque a experiência mostra que usando o mesmo número de neurónios em todas as
camadas escondidas traz tão bons, ou melhores resultados, que o esquema em pirâmide. Traz ainda a vantagem de ficarmos
só com um hyperparâmetro para afinar em vez de um por camada. De qualquer forma e dependente do conjunto de dados que 
temos em mãos, às vezes ajuda fazer a primeira camada escondida maior do que as outras.
&lt;p&gt;
Tal como o número de camadas, podemos tentar aumentar o número de neurónios gradualmente até a rede começar a 
fazer &lt;i&gt;overfitting&lt;/i&gt;.Na prática é muito mais simples e eficiente escolher um modelo com mais camadas e 
mais neurónios do que o necessário e depois usar &lt;i&gt;early stopping&lt;/i&gt; e outras técnicas de regularização para prevenir o 
&lt;i&gt;overfitting.&lt;/i&gt;
&lt;/p&gt;
&lt;h3&gt;Taxa de aprendizagem&lt;/h3&gt;
Sem dúvida o hyperparâmetro mais importante. Uma boa forma de encontrar o melhor valor é treinar o modelo durante 
umas centenas de iterações , começando com um valor bastante baixo (e.g. \(10^{-5}\)) e gradualmente ir aumentando 
até um valor alto (e.g., 10). Acompanhar este exercício com uma visualização gráfica da função de perda em vs taxa
de aprendizagem.
&lt;h3&gt;Optimizador&lt;/h3&gt;
Há vários para além do clássico &lt;i&gt;Mini-batch Gradient Descent&lt;/i&gt; e fazer uma escolha cuidada é importante.
&lt;h3&gt;Tamanho do batch&lt;/h3&gt;
Esta escolha é muito dependente do hardware que temos em mãos para treinar a rede. Valores elevados
para o tamanho do batch requeremm aceleradores de hardware (GPUs).
&lt;h3&gt;Função de activação&lt;/h3&gt;
De uma forma geral, a função de activação ReLU é uma boa escolha para ser usada pelas camadas escondidas. Para a 
camada de saída (&lt;i&gt;output layer&lt;/i&gt;), depende da tarefa em mãos.</description>
        <pubDate>Thu, 25 Jun 2020 17:00:00 +0100</pubDate>
        <link>http://localhost:4000//FT_NN_Hyperparams</link>
        <link href="http://localhost:4000/FT_NN_Hyperparams"/>
        <guid isPermaLink="true">http://localhost:4000/FT_NN_Hyperparams</guid>
      </item>
    
      <item>
        <title>Regressão MLP com dados sintéticos</title>
        <description>&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script id=&quot;MathJax-script&quot; async
          src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&quot;&gt;
&lt;/script&gt;


&lt;h2&gt;Introdução&lt;/h2&gt;
Vamos analisar a capacidade de um MLP (Multi Layer Perceptron) em aproximar quatro funções diferentes.
&lt;br&gt;
Em cada caso vamos extrair &lt;i&gt;N = 50&lt;/i&gt; pontos escolhidos uniformemente em &lt;i&gt;x&lt;/i&gt; no intervalo (-1, 1) e os
correspondentes valores &lt;i&gt;f(x)&lt;/i&gt; calculados.
&lt;br&gt;
Estes pontos serão depois usados para treinar uma rede neuronal com:
&lt;ul&gt;
	&lt;li&gt;Duas camadas com:&lt;/li&gt;
	&lt;li&gt;Três unidades escondidas com:&lt;/li&gt;
	&lt;li&gt;Funcões de activação &lt;i&gt;tanh&lt;/i&gt; e:&lt;/li&gt;
	&lt;li&gt;Unidades de saída lineares&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Nota: link para o jupyter notebook com o código completo: 
&lt;a href=&quot;https://github.com/mleiria/mleiria.github.io/blob/master/jupyter-notebook/MLP_Regression_Synthetic_Data.ipynb&quot; target=&quot;_blank&quot;&gt;MLP_Regression_Synthetic_Data.ipynb&lt;/a&gt;
&lt;/p&gt;

&lt;i&gt;Hyperparameters&lt;/i&gt; que podem ser alterados:
&lt;ul&gt;
	&lt;li&gt;Learning rate&lt;/li&gt;
	&lt;li&gt;Número de épocas&lt;/li&gt;
	&lt;li&gt;Tamanho do batch&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Módulos a importar&lt;/h3&gt;
&lt;pre&gt;
import pandas as pd
import tensorflow as tf
from matplotlib import pyplot as plt
&lt;/pre&gt;
&lt;h3&gt;Definir funções que constroem e treinam o modelo&lt;/h3&gt;
Vamos definir duas funções:
&lt;ul&gt;
	&lt;li&gt;&lt;pre&gt;build_model(my_learning_rate)&lt;/pre&gt; que constroi um modelo vazio&lt;/li&gt; 
	&lt;li&gt;&lt;pre&gt;train_model(model, feature, label, epochs)&lt;/pre&gt; que treina o modelo a partir dos exemplos (feature e label) que lhe passamos&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;
#@title Função para criar o modelo
def build_model(my_learning_rate):
    &quot;&quot;&quot;
    Cria e compila um modelo de regressão linear.
    
    Arguments:
    my_learning_rate -- a taxa de aprendizagem
    
    Returns:
    model -- o modelo compilado
    &quot;&quot;&quot;
    # O modelo mais simples de tf.keras é o sequencial
    # O modelo sequencial pode conter uma ou mais camadas
    model = tf.keras.models.Sequential()
    
    # Topografia do modelo
    # Duas camadas escondidas, cada uma com 3 unidades
    # A camada de output só tem uma unidade (visto que só queremos
    # prever um único valor) e não usa nenhuma função de activação
    model.add(tf.keras.layers.Dense(units=3, activation=&quot;tanh&quot;, input_shape=(1,)))
    model.add(tf.keras.layers.Dense(units=3, activation=&quot;tanh&quot;))
    model.add(tf.keras.layers.Dense(1))
    
    
    # Compilar a topografia do modelo
    # Configurar o treino para minimizar o erro quadrático médio
    model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),
                  loss=&quot;mean_squared_error&quot;,
                  metrics=[tf.keras.metrics.RootMeanSquaredError()])
    
    return model           

#@title Função para treinar o modelo
def train_model(model, feature, label, epochs, batch_size):
    &quot;&quot;&quot;
    Treina o modelo de acordo com os dados de entrada
    
    Arguments:
    model -- o modelo a ser treinado
    feature -- um array de features (os valores x)
    label -- um array de labels (os valores y = f(x))
    epochs -- numero de epocas de treino
    batch_size -- tamanho do batch
    
    Returns:
    epochs -- Lista de épocas
    rmse -- Raíz quadrada do erro quadrático médio
    &quot;&quot;&quot;
    
    # Preparar uma diretoria de logs para ser usada pelo tensorboard
    log_dir = &quot;logs/fit/&quot; + datetime.datetime.now().strftime(&quot;%Y%m%d-%H%M%S&quot;)
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)

    # Passa os valores das features e os valores das labels
    # para o modelo. O modelo vai treinar durante o número
    # de epochs especificado e gradualmente vai aprendendo
    # como é que os valores das features se relacionam com
    # os valores das labels
    history = model.fit(x=feature,
                        y=label,
                        batch_size=batch_size,
                        epochs=epochs,
                        callbacks=[tensorboard_callback])
    
    # Gather the trained model's weight and bias.
    trained_weight = model.get_weights()
    trained_bias = model.get_weights()
    
    # A lista das epocas e guardada em separado
    epochs = history.epoch
    
    # Faz um snapshot do historico de cada epoca
    hist = pd.DataFrame(history.history)

    # Recolhe especificamente a raiz quadrada do erro quadrático médio
    # em cada epoca
    rmse = hist[&quot;root_mean_squared_error&quot;]

    return epochs, rmse

&lt;/pre&gt;
&lt;h3&gt;Definir funções auxiliares para visualizar os resultados&lt;/h3&gt;
Vamos definir duas funções de forma a conseguirmos visualizar o modelo
e a curva de perda:
&lt;ul&gt;
	&lt;li&gt;&lt;pre&gt;plot_the_model(feature, label, preds)&lt;/pre&gt; que mostra os pontos originais e uma linha com os pontos previstos pela rede&lt;/li&gt; 
	&lt;li&gt;&lt;pre&gt;plot_the_loss_curve(epochs, rmse)&lt;/pre&gt; que mostra a curva de perda em função das épocas&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;
#@title Gráfico para mostrar o modelo treinado
def plot_the_model(feature, label, preds):
    &quot;&quot;&quot;
    Gráfico que mostra o modelo treinado contra as features e labels
    
    Arguments:
    feature -- array de features que passámos à rede para treino
    label -- array de labels correspondentes às features
    preds -- array de valores previstos pelo modelo
    &quot;&quot;&quot;
    
    # Nomes para os eixos
    plt.xlabel(&quot;feature&quot;)
    plt.ylabel(&quot;label&quot;)
    
    # Valores das features vs. valores das labels
    plt.scatter(feature, label)
    
    # Cria uma representação a encarnado do modelo.
    plt.plot(feature, preds, 'r--')
    
    # Faz o render do scatter plot e da linha encarnada
    plt.show()

#@title Gráfico para mostrar o rmse vs. epochs
def plot_the_loss_curve(epochs, rmse):
    &quot;&quot;&quot;
    Gráfico da curva de perda (loss vs. epoch)
    
    Arguments:
    epochs -- número de épocas
    rms -- erro quadrático médio
    
    &quot;&quot;&quot;
    
    plt.figure()
    plt.xlabel(&quot;Epoch&quot;)
    plt.ylabel(&quot;Root Mean Squared Error&quot;)
    
    plt.plot(epochs, rmse, label=&quot;Loss&quot;)
    plt.legend()
    plt.ylim([rmse.min()*0.97, rmse.max()])
    plt.show()

&lt;/pre&gt;
&lt;h3&gt;Definir o conjunto de dados&lt;/h3&gt;
Vamos definir quatro funções para as quais queremos que a rede neuronal aprenda a sua representação:
&lt;ol&gt;
	&lt;li&gt;\(f(x) = x^2\)&lt;/li&gt;
	&lt;li&gt;\(f(x) = sin(x)\)&lt;/li&gt;
	&lt;li&gt;\(f(x) = |x|\)&lt;/li&gt;
	&lt;li&gt;\(f(x) = H(x)\)&lt;/li&gt;
&lt;/ol&gt;
onde \(H(x)\) é a função Heaviside.
&lt;pre&gt;
def draw_points(n, func):
    &quot;&quot;&quot;
    Constroi conjuntos de dados de acordo com a função escolhida
    
    Arguments:
    n -- Total de pontos
    func -- Tipo de função (Aceita: sin, power_two, abs, heaviside)
    
    Returns:
    feature -- Um array com as features (valores de x)
    label -- Um array com as labels (valores de y = f(x))
    &quot;&quot;&quot;
    feature = np.sort(np.random.uniform(-1, 1, n))
    if func == 'sin':
        label = np.sin(feature)
    elif func == 'power_two':
        label = np.power(feature, 2)
    elif func == 'abs':
        label = np.abs(feature)
    elif func == 'heaviside':
        label = np.heaviside(feature, 0)
    else:
        print(&quot;Erro&quot;)
        return 0, 0
        
    return feature, label    
&lt;/pre&gt;
Podemos agora gerar dados e ver a rede em acção:
&lt;pre&gt;
# Escolher uma das seguintes funções:
# my_feature, my_label = draw_points(50, func='power_two')
# my_feature, my_label = draw_points(50, func='sin')
# my_feature, my_label = draw_points(50, func='abs')

#Heaviside
my_feature, my_label = draw_points(50, func='heaviside')
&lt;/pre&gt;
&lt;h3&gt;Configurar os &lt;i&gt;Hyperparameters&lt;/i&gt; e treinar o modelo&lt;/h3&gt;
Aqui podemos experimentar diversas combinações dos &lt;i&gt;Hyperparameters&lt;/i&gt; para tentar obter o 
melhor ajustamento.

&lt;pre&gt;
# Limpa os logs das iterações anteriores
!rm -rf ./logs/ 
    
#Hyperparameters
learning_rate=0.01
epochs=100
my_batch_size=10

my_model = build_model(learning_rate)
epochs, rmse = train_model(my_model, my_feature, my_label, epochs, my_batch_size)	
&lt;/pre&gt;
&lt;h3&gt;Fazer previsões e visualizar os resultados.&lt;/h3&gt;
&lt;pre&gt;
# Fazer previsões
preds = my_model.predict(my_feature)
preds = np.squeeze(preds)

# Ver os resultados
plot_the_model(my_feature, my_label, preds)
plot_the_loss_curve(epochs, rmse)
&lt;/pre&gt;
Para este caso concreto da aproximação à função de Heaviside,
os parâmetros aprendidos pela rede neuronal é razoável:
&lt;img src=&quot;../images/2020-06-24-MLP_Regression_Sythetic_Data_2.png&quot;&gt;&lt;br&gt;
No gráfico de cima, Os pontos a azul representam os dados reais. Os traços a encarnado mostram
os outputs do modelo treinado. Idealmente a linha vermelha deve alinhar com os pontos azuis.
Há uma certa aleatoriedade quando o modelo é treinado, de forma que os resultados em cada treino
poderão ser ligeiramente diferentes.
O gráfico de baixo mostra a curva de perda. Podemos ver que a curva decresce, o que é bom, mas 
não fica plana, que é um indicativo que o modelo não treinou o suficiente.
Se alterarmos os &lt;i&gt;Hyperparameters&lt;/i&gt;:
&lt;pre&gt;
#Hyperparameters
learning_rate=0.01
epochs=200
my_batch_size=20
&lt;/pre&gt;
obtemos,
&lt;img src=&quot;../images/2020-06-24-MLP_Regression_Sythetic_Data_3.png&quot;&gt;
&lt;br&gt;
que melhora o ajuste.
&lt;h3&gt;Sumário aos ajustes dos &lt;i&gt;Hyperparameters&lt;/i&gt;.&lt;/h3&gt;
A maior parte dos problemas de machine learning requerem ajustes em vários parâmetros e o problema é que não há uma receita para cada modelo.&lt;br&gt;
Se baixarmos a taxa de aprendizagem (learning rate) podemos ajudar determinado modelo a convergir de forma eficiente mas pode fazer com que um outro modelo convirja lentamente. Há que experimentar
várias combinações do conjunto de &lt;i&gt;Hyperparameters&lt;/i&gt; de acordo com o conjunto de dados em estudo. Dito isto, há algumas &quot;regras&quot; para ajudar a escolher os &lt;i&gt;Hyperparameters&lt;/i&gt;:

&lt;ul&gt;
	&lt;li&gt;A função de perda do treino deve decrescer, primeiro de uma forma acentuada e depois mais lentamente até que o declive da curva se apróxima de zero.&lt;/li&gt;
	&lt;li&gt;Se a função de perda do treino não convergir =&gt; aumenta o número de épocas&lt;/li&gt;
	&lt;li&gt;Se a função de perda do treino decresce muito lentamente =&gt; aumenta a taxa de aprendizagem (learning rate). Atenção porque se a taxa for muito elevada
		pode fazer com que não haja convergência.&lt;/li&gt;
	&lt;li&gt;Se a função de perda do treino varia de forma descontrolada (altos e baixos acentuados) =&gt; diminui a taxa de aprendizagem&lt;/li&gt;
	&lt;li&gt;Diminuir a taxa de aprendizagem e aumentar o número de épocas ou o tamanho do batch, regra geral, é uma boa combinação.&lt;/li&gt;
	&lt;li&gt;Baixar muito o tamanho do batch pode causar alguma instabilidade. Primeiro tenta-se um valor elevado para o tamanho do batch e depois vai-se baixando 
		aos poucos.&lt;/li&gt;
	&lt;li&gt;&lt;b&gt;Importante:&lt;/b&gt; A combinação ideal de &lt;i&gt;Hyperparameters&lt;/i&gt; é dependente do conjunto de dados em análise, de forma que devemos sempre experimentar
	várias combinações e verificar os resultados de forma a encontrar a combinação ideal.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Arquitectura típica de regressão MLP&lt;/h3&gt;
&lt;table&gt;
    &lt;tr&gt;&lt;th&gt;Hyperparameter&lt;/th&gt;&lt;th&gt;Valores típicos&lt;/th&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;# unidades de entrada (&lt;i&gt;input neurons&lt;/i&gt;)&lt;/td&gt;&lt;td&gt;Uma por feature de entrada&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;# camadas escondidas (&lt;i&gt;hidden layers&lt;/i&gt;)&lt;/td&gt;&lt;td&gt;Depende mas tipicamente de 1 a 5&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;# unidades por camada escondida (&lt;i&gt;neurons per hidden layer&lt;/i&gt;)&lt;/td&gt;&lt;td&gt;Depende mas tipicamente de 10 a 100&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;# unidades de saída (&lt;i&gt;output neurons&lt;/i&gt;)&lt;/td&gt;&lt;td&gt;1 por cada dimensão de previsão&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Activação das camadas escondidas (&lt;i&gt;Hidden activation&lt;/i&gt;)&lt;/td&gt;&lt;td&gt;ReLU&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Activação da saída (&lt;i&gt;output activation&lt;/i&gt;)&lt;/td&gt;&lt;td&gt;Nenhuma ou ReLU/softplus (se queremos outputs positivos) ou logistic/tanh (se queremos outputs limitados)&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td&gt;Função de perda (&lt;i&gt;loss function&lt;/i&gt;)&lt;/td&gt;&lt;td&gt;MSE ou MAE/Huber (se houver outliers)&lt;/td&gt;&lt;/tr&gt;

&lt;/table&gt;


</description>
        <pubDate>Thu, 25 Jun 2020 17:00:00 +0100</pubDate>
        <link>http://localhost:4000//Regressao-MLP-Dados-Sinteticos</link>
        <link href="http://localhost:4000/Regressao-MLP-Dados-Sinteticos"/>
        <guid isPermaLink="true">http://localhost:4000/Regressao-MLP-Dados-Sinteticos</guid>
      </item>
    
      <item>
        <title>Regressão Linear com TensorFlow. O essencial.</title>
        <description>&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script id=&quot;MathJax-script&quot; async
          src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&quot;&gt;
&lt;/script&gt;


&lt;h2&gt;Introdução&lt;/h2&gt;
Podemos definir um algoritmo de machine learning como um algoritmo que é capaz melhorar
a capacidade computacional de um programa a executar determinada tarefa através da experiência.&lt;br&gt;
Sendo esta definição um pouco abstracta, vamos apresentar um exemplo concreto: &lt;b&gt;regressão linear&lt;/b&gt;.&lt;br&gt;
Como o nome indica, o objectivo é construir um sistema que receba um vector \(\mathbf x \in R^n\) como input e prever
o valor de um escalar \(y \in R\) como output. O output da regressão linear é uma função linear do input.&lt;br&gt;
Seja \(\hat y\) o valor que o nosso modelo prevê que o valor real \(y\) deve tomar. Podemos definir o output
como:&lt;p&gt;
	\[\hat y = \mathbf w^T \mathbf x\]
&lt;/p&gt;
onde \(\mathbf w \in R^n\) é o vector de &lt;b&gt;parâmetros&lt;/b&gt;.&lt;br&gt;
Os parâmetros são os valores que controlam o comportamento do sistema. Neste caso, \(w_i\) é o coeficiente
que multiplicamos pelo valor de entrada (&lt;i&gt;feature&lt;/i&gt;) \(x_i\) antes de somarmos todas as contribuições
de todos os valores de entrada. Podemos pensar em \(\mathbf w\) como um conjunto de &lt;b&gt;pesos&lt;/b&gt; que determinam como
cada valor de entrada afecta a previsão.&lt;br&gt;
Se um valor de entrada \(x_i\) recebe um peso positivo \(w_i\), então, aumentando esse valor vai provocar um aumento 
no valor previsto \(\hat y\).&lt;br&gt;
Se um valor de entrada \(x_i\) recebe um peso negativo \(w_i\), então, aumentando esse valor vai provocar um decréscimo 
no valor previsto \(\hat y\).&lt;p&gt;
Desta forma temos a definição da nossa tarefa &lt;i&gt;T&lt;/i&gt;: prever \(y\) a partir de \(\mathbf x\) usando \(\hat y = \mathbf w^T\mathbf x\).&lt;br&gt;
O próximo passo é deifinir uma medida de &lt;i&gt;performance&lt;/i&gt; &lt;i&gt;P&lt;/i&gt;.
&lt;/p&gt;
Uma das formas de medir esta &lt;i&gt;performance&lt;/i&gt; é calculando o &lt;b&gt;erro quadtrático médio&lt;/b&gt; do modelo no conjunto de dados de teste. Se
\( \mathbf{ \hat y}^{(test)} \) dá-nos a previsão do modelo no conjunto de dados de teste, então o erro quadtrático médio é dado por:&lt;p&gt;

	\[ MSE_{test} = \frac{1}{m} \sum_i (\mathbf{ \hat y}^{(test)} - \mathbf{y}^{(test)})^2_i\]
&lt;br&gt;
ou, alternativamente
&lt;br&gt;
	\[ MSE_{test} = \frac{1}{m} \| \mathbf{ \hat y}^{(test)} - \mathbf{y}^{(test)}\|^2_2\]
&lt;/p&gt;
Intuitivamente podemos ver que esta medida de erro decresce para 0 quando \( \mathbf{ \hat y}^{(test)} = \mathbf{ y}^{(test)} \)
&lt;h2&gt;Procedimento&lt;/h2&gt;
Para fazermos um algoritmo de machine learning, temos de desenhar um algoritmo que melhore os pesos \( \mathbf w\) de uma maneira que reduza 
o \( MSE_{test} \) quando é permitido ao algoritmo ganhar experiência através da observação do conjunto de dados de treino \( (\mathbf X^{(train)}, \mathbf Y^{(train)}) \).&lt;br&gt;
A forma mais natural de minimizar este erro é obter o gradiente e igualá-o a zero:&lt;p&gt;

	\[ \nabla_w MSE_{train} = 0 \]
	\[ \Rightarrow \nabla_w \frac{1}{m} \| \mathbf{ \hat y}^{(train)} - \mathbf{y}^{(train)}\|^2_2 = 0\]
	\[ \Rightarrow \frac{1}{m} \nabla_w  \| \mathbf X^{(train)} \mathbf w - \mathbf{y}^{(train)}\|^2_2 = 0\]
	\[ \Rightarrow \mathbf w = (\mathbf X^{(train)T} \mathbf X^{(train)})^{-1} \mathbf X^{(train)T} \mathbf y^{(train)} \]
&lt;/p&gt; 
Vale a pena referir que o termo &lt;b&gt;regressão linear&lt;/b&gt; é usado exprimir um modelo ligeiramente mais sofisticado, com um parâmetro adicional - 
um termo de intersecção \(b\):&lt;p&gt;
	\[\hat y = \mathbf w^T \mathbf x + b\]
&lt;/p&gt;
&lt;h2&gt;TensorFlow&lt;/h2&gt;
Tentando manter as coisas simples, vamos usar TensorFlow para converter graus Celsius para Fahrenheit. A fórmula aproximada é:&lt;p&gt;
	\[ f = 1.8c + 32\]
&lt;/p&gt;

o exercício será passarmos ao TensorFlow uma amostra de dados Celcius e os seus correspondentes Fahrenheit. Depois, treinamos um modelo que
replique a fórmua supra de conversão, através de um processo de treino.&lt;br&gt;
&lt;br&gt;
&lt;h4&gt;1 - Importar dependências&lt;/h4&gt;

&lt;pre&gt;
import tensorflow as tf
import numpy as np
&lt;/pre&gt;

&lt;br&gt;
&lt;h4&gt;2 - Preparar o conjunto de dados de treino&lt;/h4&gt;
Este é um algoritmo de machine learning supervisionado porque vamos mostrar ao modelo alguns exemplos de conversão e queremos que ele nos
dê uma fórmula generalizada:&lt;br&gt;

&lt;pre&gt;
celsius_q    = np.array([-40, -10,  0,  8, 15, 22,  38],  dtype=float)
fahrenheit_a = np.array([-40,  14, 32, 46, 59, 72, 100],  dtype=float)
&lt;/pre&gt;

NOTA: Alguma terminologia para o que se segue:&lt;p&gt;
&lt;ul&gt;
	&lt;li&gt;
&lt;b&gt;Feature&lt;/b&gt; - os valores de input para o nosso modelo. Neste caso é um só valor: os graus em Celcius.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;Labels&lt;/b&gt; - o output que o nosso modelo vai prever. Neste caso é um só valor: os graus em Fahrenheit.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;Exemplo&lt;/b&gt; - um par de valores input/output usados na fase de treino. Neste caso é um par de valores (Celcius, Fahrenheit)
&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

&lt;h4&gt;3 - Criar o modelo&lt;/h4&gt;
O passo seguinte é criar o modelo. Como este é um problema muito simples basta-nos criar uma rede com uma única camada
e um único nó.
&lt;br&gt;

&lt;h4&gt;3.1 - Construir a camada (&lt;i&gt;layer&lt;/i&gt;)&lt;/h4&gt;

&lt;pre&gt;l0 = tf.keras.layers.Dense(units=1, input_shape=[1])&lt;/pre&gt;
onde
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;l0&lt;/i&gt;: Nome da camada&lt;/li&gt;
&lt;li&gt;&lt;i&gt;input_shape=[1]&lt;/i&gt;: Especifica que o input desta camada é um único valor, ou seja, a forma é um array de uma dimensão com um membro.
O valor é do tipo float e representa os graus Celcius&lt;/li&gt;
&lt;li&gt;&lt;i&gt;units=1&lt;/i&gt;:Especifica o número de neurónios (ou nós, ou unidades) na camada. O número de neurónios define quantas variáveis internas 
a camada tem para tentar resolver o problema&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;h4&gt;3.2 - Adicionar a camada ao modelo&lt;/h4&gt;
Uma vez definidas as camadas, podemos adicioná-las ao modelo. O modelo sequencial recebe uma lista de camadas como argumento que especifica 
a ordem de cálculo desde o input até ao output. No nosso caso só temos uma camada:
&lt;pre&gt;
model = tf.keras.Sequential([l0])
&lt;/pre&gt;
&lt;br&gt;
&lt;h4&gt;4 - Compilar o modelo com as funções de perda e otimizador&lt;/h4&gt;
Antes de treinar o modelo, é necessário compilar, definindo duas funções importantes:
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Função de perda (&lt;i&gt;loss function&lt;/i&gt;)&lt;/b&gt;: uma forma de medir o quão afastado está o valor previsto pela rede do valor real. Neste caso
faz sentido usar o erro quadrático médio.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Função otimizadora&lt;/b&gt;: uma forma de ajustar os valores internos de forma a reduzir a perda.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))&lt;/pre&gt;
Estas funções serão utilizadas durante a fase de treino (&lt;i&gt;model.fit()&lt;/i&gt;), primeiro para calcular a perda em cada ponto e posteriormente
melhorá-la.
&lt;br&gt;
Note-se que o otimizador Adam, recebe um argumento, o &lt;i&gt;learning rate&lt;/i&gt;. Este é um hyperparâmetro e representa o comprimento do passo a ser dado, em cada
iteração, quando o modelo ajusta os seus valores. Normalmente escolhemos um valor entre 0.001 e 0.1.

&lt;br&gt;&lt;br&gt;
&lt;h4&gt;5 - Treinar o modelo&lt;/h4&gt;
O treino do modelo é feito invocando o método &lt;i&gt;fit()&lt;/i&gt;.&lt;br&gt;
Durante o treino o modelo vai receber os valores em graus Celcius, fazer algumas contas usando os pesos e retorna como output o que ele considera
ser a conversão para Fahrenheit. Como os pesos vão ser inicializados com valore aleatórios, o primeiro output não vai ter nada a ver com o valor
correcto da conversão. Depois é utilizada a função de perda para calcular o quão afastado o outuput está do valor real. Por fim a função de otimização
reajusta os pesos de forma a aproximar o output do valor real.
&lt;p&gt;
Este ciclo de calcular, comparar e ajustar é controlado pelo ḿétodo &lt;i&gt;fit()&lt;/i&gt;: o primeiro argumento são os inputs (graus Celcius), o segundo argumento
são os outputs desejados (graus Fahrenheit). O argumento &lt;i&gt;epochs&lt;/i&gt; especifica quantas vezes este ciclo deve ser executado
&lt;/p&gt;
&lt;pre&gt;history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)&lt;/pre&gt;
&lt;br&gt;
&lt;h4&gt;6 - Mostrar as estatísticas do treino&lt;/h4&gt;
O método &lt;i&gt;fit()&lt;/i&gt; retorna um objecto de histórico. Podemos usar este objecto para analisar como é que a perda evolui ao longo das épocas. 
&lt;br&gt;
Uma perda elevada diz-nos que a conversão para Fahrenheit prevista pelo nosso modelo está longe do valor verdadeiro. Vejamos o aspeto da 
curva de perda:
&lt;pre&gt;
import matplotlib.pyplot as plt
plt.xlabel('Epoch')
plt.ylabel(&quot;Root Mean Squared Error&quot;)
plt.plot(history.history['loss'])
&lt;/pre&gt;
&lt;img src=&quot;../images/2020-06-04-LossCurve.png&quot; alt=&quot;Loss curve&quot;&gt;
&lt;br&gt;&lt;br&gt;
&lt;h4&gt;6 - Usar o modelo para fazer previsões&lt;/h4&gt;
Com o modelo treinado, estamos em condições de fazer previsões, i.e., apresentar um determinado valor (graus Celcius) à rede neuronal e obter
o respetivo valor em Fahrenheit.&lt;br&gt;
Por exemplo, 100º Celcius corresponde a quantos graus Fahrenheit? Note-se que este valor não foi apresentado à rede na fase de treino.
&lt;pre&gt;print(model.predict([100.0]))&lt;/pre&gt;
[[211.75616]]
&lt;br&gt;&lt;br&gt;
A resposta correta (utilizando a fórmula de conversão), é:&lt;p&gt;
	100×1.8+32=212
&lt;/p&gt;
Não está nada mal!
&lt;br&gt;&lt;br&gt;
Resumindo:
&lt;ul&gt;
&lt;li&gt;Criar o modelo&lt;/li&gt;
&lt;li&gt;Treinar o modelo com 35000 exemplos (7 pares em 500 épocas)&lt;/li&gt;
&lt;/ul&gt;
O nosso modelo foi afinando os pesos na camada densa até conseguir retornar o valor correto em Fahrenheit para qualquer valor Celcius.
&lt;br&gt;&lt;br&gt;
Por último podemos ver os valores finais dos pesos determinados pela rede:
&lt;pre&gt;print(&quot;These are the layer variables: {}&quot;.format(l0.get_weights()))&lt;/pre&gt;

[array([[1.7974412]], dtype=float32), array([31.949804], dtype=float32)]
&lt;br&gt;&lt;br&gt;
A primeira variável está próxima de \(~1.8\) e a segunda, próxima de \(~32\). Estes valores (\(1.8\) e \(32\)) são os valores da fórmula 
de conversão.
&lt;p&gt;
	O código completo está aqui: &lt;a href=&quot;https://github.com/mleiria/mleiria.github.io/blob/master/jupyter-notebook/Linear_Regression_Tensorflow.ipynb&quot; target=&quot;_blank&quot;&gt;Linear_Regression_Tensorflow.ipynb&lt;/a&gt;
	
&lt;/p&gt;



</description>
        <pubDate>Thu, 04 Jun 2020 17:50:00 +0100</pubDate>
        <link>http://localhost:4000//Linear-Regression-Tensorflow</link>
        <link href="http://localhost:4000/Linear-Regression-Tensorflow"/>
        <guid isPermaLink="true">http://localhost:4000/Linear-Regression-Tensorflow</guid>
      </item>
    
      <item>
        <title>Álgebra Linear. O essencial.</title>
        <description>&lt;script src=&quot;https://polyfill.io/v3/polyfill.min.js?features=es6&quot;&gt;&lt;/script&gt;
&lt;script id=&quot;MathJax-script&quot; async
          src=&quot;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&quot;&gt;
&lt;/script&gt;

&lt;h2&gt;Multiplicação de Matrizes e Vectores&lt;/h2&gt;
&lt;p&gt;Uma das mais importantes operações que envolvem matrizes é a multiplicação de duas matrizes.&lt;/p&gt;
O &lt;b&gt;produto matricial&lt;/b&gt; entre duas matrizes \(A\) e \(B\) é uma terceira matriz \(C\).&lt;br&gt;
Para este produto ser definido, a matriz \(A\) tem de ter o mesmo número de colunas que o número de linhas
da matriz \(B\).&lt;br&gt;
Se \(A\) tiver dimensões (\(m\) x \(n\)), onde \(m\) representa o número de linhas e \(m\) é o número de colunas e \(B\) tiver dimensões 
\((n\) x \(p\)), então \(C\) terá dimensões (\(m\) x \(p\)).&lt;br&gt;
Por exemplo:&lt;p&gt;
	
	\[C = AB\]
&lt;/p&gt;
Esta operação é definida da seguinte forma:&lt;p&gt;

	\[C_{i,j} = \sum_{k} A_{i,k} B_{k,j}\]
&lt;/p&gt;
Atenção que este produto não corresponde ao produto dos elementos individuais. Este produto também existe e chama-se &lt;b&gt;produto Hadamard&lt;/b&gt; ou 
&lt;b&gt;produto elemento a elemento &lt;/b&gt;(&lt;i&gt;element-wise&lt;/i&gt;) e denota-se 
por \(A \odot B\)
&lt;p&gt;
O &lt;b&gt;produto vectorial&lt;/b&gt; (&lt;i&gt;dot product&lt;/i&gt;) entre dois vectores \(x\) e \(y\) com a mesma dimensão, é o produto matricial \(x^T y\)&lt;br&gt;
O produto matricial apresenta algumas propriedades úteis. Por exemplo a distributividade:&lt;p&gt;
	\[A(B + C) = AB + AC\]
&lt;/p&gt;Também é associativo:&lt;p&gt;
	\[A(BC) = (AB)C\]
&lt;/p&gt;
A multiplicação matricial &lt;i&gt;não é comutativa&lt;/i&gt; (a condição \(AB = BA\) nem sempre é válida). No entanto o produto vectorial entre dois
vectores é comutativa:&lt;p&gt;
	\[x^Ty = y^Tx\]
&lt;/p&gt;
A matriz transposta do produto de duas matrizes é:&lt;p&gt;
	\[(AB)^T = B^TA^T\]
&lt;/p&gt;
&lt;h2&gt;Identidade e Matriz Inversa&lt;/h2&gt;
Para descrever a matriz inversa, precisamos primeiro definir o conceito de &lt;b&gt;matriz identidade&lt;/b&gt;. Uma matriz identidade é uma matriz que
não altera qualquer vector que for multiplicado por ela. Formalmente, \(I_{n} \in R^{nxn}\) e &lt;p&gt;
	\[\forall x \in R^{n}, I_nx = x\]
&lt;/p&gt;
A estrutura da matriz identidade é simples: todas as entradas da diagonal principal são 1 e todas as outras são 0. Por exemplo:&lt;p&gt;
	\[I_3 = \begin{bmatrix}1 &amp; 0 &amp; 0\\0 &amp; 1 &amp; 0 \\0 &amp; 0&amp; 1\end{bmatrix}\]
&lt;/p&gt;
A &lt;b&gt;matriz inversa&lt;/b&gt; de \(A\), denota-se por \(A^{-1}\) e é difinida como a matriz tal que:&lt;p&gt;
	\[A^{-1} A =I_n\]
&lt;/p&gt;
Consideremos como exercício final o seguinte sistema de equações lineares:&lt;p&gt;
	\[A x = b\]
&lt;/p&gt;
onde \(A \in R^{mxn}\) é uma matriz com os valores conhecidos, \(b \in R^m\) é um vector conhecido e \(x \in R^{n}\) é o vector de variáveis 
desconhecidas para o qual pretendemos resolver o sistema. Esta equação resolve-se seguindo os seguintes passos:&lt;p&gt;
	\[A x = b\]
	\[A^{-1}A x = A^{-1}b\]
	\[I_n x = A^{-1}b\]
	\[x = A^{-1}b\]
&lt;/p&gt;
&lt;h2&gt;Norma&lt;/h2&gt;
Em &lt;i&gt;machine learning&lt;/i&gt; normalmente mede-se o comprimento de um vector usando uma função chamada &lt;b&gt;norma&lt;/b&gt;. Formalmente,
a norma \(L^p\) é dada por:&lt;p&gt;
	\[||x||_p = (\sum_i |x_i|^p)^{1/p}\]
para \(p \in R, p \geq 1\)
&lt;/p&gt;
As normas são funções que mapeiam vectores para valores não negativos. Intiuitivamente podemos pensar que a norma de um vector \(x\) 
mede a distância da origem ao ponto \(x\). Sendo um pouco mais rigorosos, a norma é qualquer função \(f\) que satisfaz as seguintes propriedades:&lt;p&gt;
	&lt;ul&gt;
		&lt;li&gt;\(f(x) = 0\ \Rightarrow x = 0\)&lt;/li&gt;
		&lt;li&gt;\(f(x + y) \leq f(x) + f(y)\)&lt;/li&gt;
		&lt;li&gt;\(\forall \alpha \in R, f(\alpha x) = |\alpha|f(x)\)&lt;/li&gt;
	&lt;/ul&gt;
&lt;/p&gt;
A norma \(L^2\) (quando \(p = 2\)) é conhecida como a &lt;b&gt;norma Euclideana&lt;/b&gt;, que é simplesmente a distância euclideana da origem ao ponto 
identificado por \(x\). Costuma-se designar por \(||x||\), onde o \(2\) é omitido na notação.&lt;br&gt;
Também é bastante comum medir o comprimento de um vector usando o quadrado da norma \(L^2\), que pode ser calculado simplesmente como
\(x^Tx\)&lt;br&gt;
A norma \(L^1\) também é bastante utilizada:&lt;p&gt;
	\[||x||_1 = \sum_i |x_i|\]
&lt;/p&gt;
Outra norma bastante utilizada nesta área é a norma \(L^\infty\), também conhecida como &lt;b&gt;norma máxima&lt;/b&gt; (&lt;i&gt;max norm&lt;/i&gt;):&lt;p&gt;
	\[||x||_\infty = \mathrm{max}_i|x_i|\]
&lt;/p&gt;
Por fim, muitas vezes é necessário calcular o comprimento de uma matriz. No contexto de &lt;i&gt;deep learning&lt;/i&gt; a norma mais utilizada 
é a &lt;b&gt;norma Frobenius&lt;/b&gt;:&lt;p&gt;
	\[||A||_F = \sqrt{\sum_{i,j} A^2_{i,j}}\]
&lt;/p&gt;
que é semelhante à norma \(L^2\) de um vector.&lt;br&gt;
	O produto vectorial de dois vectores pode ser escrito em termos das suas normas:&lt;p&gt;
		\[x^Ty = ||x||_2 ||y||_2 cos \theta\]
&lt;/p&gt;
onde \(\theta\) é o ângulo entre \(x\) e \(y\)
&lt;h2&gt;Matrizes e vectores especiais&lt;/h2&gt;
&lt;h3&gt;Matriz diagonal&lt;/h3&gt;
Esta matriz só apresenta valores diferentes de zero na sua diagonal principal. Formalmente, uma matriz \(D\) é diagonal se e só se \(D_{i,j} = 0\) para todos
os \(i \neq j\). Já vimos um exemplo de uma matriz diagonal: a matriz identidade, onde todas as entradas na diagonal principal são 1.
&lt;h3&gt;Matriz simétrica&lt;/h3&gt;
É qualquer matriz tal que é igual à sua transposta:&lt;p&gt;
	\[A = A^T\]
&lt;/p&gt;
&lt;h3&gt;Vector unitário&lt;/h3&gt;
É um vector com a &lt;b&gt;norma unitária&lt;/b&gt;:&lt;p&gt;
	\[||x||_2 = 1\]
&lt;/p&gt;
Um vector \(x\) e um vector \(y\) são ortogonais entre si, se \(x^Ty = 0\). Se ambos os vectores tiverem uma norma diferente de zero, isto quer dizer que formam um 
ângulo de \(90^0\) entre si. Se dois vectores forem ortogonais e tiverem norma unitária, chamam-se &lt;b&gt;ortonormais&lt;/b&gt;.
&lt;h3&gt;Matriz ortogonal&lt;/h3&gt;
É uma matriz quadrada cujas linhas são mutualmente ortonormais e cujas colunas são mutualmente ortonormais:&lt;p&gt;
	\[A^TA = AA^T = I\]
&lt;/p&gt;
Isto implica que:&lt;p&gt;
	\[A^{-1} = A^T\]
&lt;/p&gt;
Estas matrizes são interessantes porque a sua inversa é computacionalmente fácil de obter.
&lt;p&gt;
&lt;script src=&quot;https://gist.github.com/mleiria/4f27f0361a01d8485e103b2a73ae8080.js&quot;&gt;&lt;/script&gt;
&lt;/p&gt;
</description>
        <pubDate>Thu, 04 Jun 2020 17:50:00 +0100</pubDate>
        <link>http://localhost:4000//Algebra-Linear</link>
        <link href="http://localhost:4000/Algebra-Linear"/>
        <guid isPermaLink="true">http://localhost:4000/Algebra-Linear</guid>
      </item>
    
  </channel>
</rss>
